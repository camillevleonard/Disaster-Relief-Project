---
title: "Semester Project Part 1 Camille Leonard"
output: html_notebook
---


```{r}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 7,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=FALSE,     # do not show R warnings
                      message=FALSE)     # do not show R messages
```

```{r}
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(yardstick) #for ROC curves...?
library(caret)
library(pROC)
library(class)
```

```{r}
df <- tibble(read.csv("HaitiPixels.csv"))
anyNA(df)
summary(df)
ggpairs(df[,2:4], lower.panel = NULL)
df$Class <- factor(df$Class)
attach(df)
```

```{r}

#par(las=2)
#boxplot(Red~Class)
#boxplot(Green~Class)
#boxplot(Blue~Class)


featurePlot(x = df[,2:4],
            y = df$Class,
            plot = "box",
            layout = c(3,1), 
            scales = list(y = list(relation = "free"),
                          x = list(rot = 90)))
```

```{r}
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1)))
attach(df)
Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not)
df
tail(df)

```


```{r}
set.seed(4)
trainIndex <- createDataPartition(Class, p=0.8,
                                  list=FALSE,
                                  times=1)

blueTarpTrain <- df[trainIndex,]
blueTarpTrain$Blue_Tarp_or_Not <- as.factor(blueTarpTrain$Blue_Tarp_or_Not)
blueTarpTrain <- blueTarpTrain[,-1]
blueTarpTest <- df[-trainIndex,]
blueTarpTest$Blue_Tarp_or_Not <- as.factor(blueTarpTest$Blue_Tarp_or_Not)
blueTarpTest <- blueTarpTest[,-1]

```


##Logistic Regression 

```{r}
glm.fit <- glm(Blue_Tarp_or_Not~Red+Green+Blue, family = binomial, data=blueTarpTrain)
summary(glm.fit)
glm.prob <- predict(glm.fit, blueTarpTest, type = "response")
glm.pred=ifelse(glm.prob>0.5,1,0)
cm.glm <- confusionMatrix(factor(glm.pred), factor(blueTarpTest$Blue_Tarp_or_Not)) 
cm.glm

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, glm.pred, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one
```

One vs the rest for logistic regression of different classes 

##LDA 

```{r}
#fitControl <- trainControl(method = "cv")

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)

set.seed(4)
lda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="lda",
                    verbose= FALSE,
                    trControl= fitControl)

lda.fit

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, lda.fit$fitted.values, plot=TRUE, print.auc=TRUE, col="purple") 

```

##QDA 

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)

set.seed(4)
qda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="qda",
                    verbose= FALSE,
                    trControl= fitControl)

qda.fit


```
## Base R KNN
```{r}

knn.pred<-knn(data.frame(blueTarpTrain), data.frame(blueTarpTest), blueTarpTrain$Blue_Tarp_or_Not, k=10)
#summary(knn.pred)
cm.knn <- confusionMatrix(knn.pred, blueTarpTest$Blue_Tarp_or_Not)
cm.knn

table(knn.pred, blueTarpTest$Blue_Tarp_or_Not)
mean(knn.pred==blueTarpTest$Blue_Tarp_or_Not)
```



## KNN
```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10, #number of folds
                           repeats = 10) # number of times each fold is run; can the number of repeats be reduced? do both of these need to be 10?

set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="knn",
                    trControl= fitControl,
                    tuneLength=10
                    )

knn.fit

```


