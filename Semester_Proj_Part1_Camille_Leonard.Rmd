---
title: "Semester Project Part 1 Camille Leonard"
output: html_notebook
---


```{r}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 7,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=FALSE,     # do not show R warnings
                      message=FALSE)     # do not show R messages
```

```{r}
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(yardstick) #for ROC curves...?
library(caret)
library(pROC)
library(class)
library(stats)
```

```{r}
df <- tibble(read.csv("HaitiPixels.csv"))
anyNA(df)
summary(df)
ggpairs(df[,2:4], lower.panel = NULL)
df$Class <- factor(df$Class)
attach(df)
```

```{r}

#par(las=2)
#boxplot(Red~Class)
#boxplot(Green~Class)
#boxplot(Blue~Class)


featurePlot(x = df[,2:4],
            y = df$Class,
            plot = "box",
            layout = c(3,1), 
            scales = list(y = list(relation = "free"),
                          x = list(rot = 90)))
```

```{r}
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1)))
attach(df)
Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not)
df
tail(df)

```


```{r}
set.seed(4)
trainIndex <- createDataPartition(Class, p=0.8,
                                  list=FALSE,
                                  times=1)

blueTarpTrain <- df[trainIndex,]
blueTarpTrain$Blue_Tarp_or_Not <- as.factor(blueTarpTrain$Blue_Tarp_or_Not)
blueTarpTrain <- blueTarpTrain[,-1]
blueTarpTest <- df[-trainIndex,]
blueTarpTest$Blue_Tarp_or_Not <- as.factor(blueTarpTest$Blue_Tarp_or_Not)
blueTarpTest <- blueTarpTest[,-1]

```


##Logistic Regression 

```{r}
#need to do CV on the GLM model... 

glm.fit <- glm(Blue_Tarp_or_Not~Red+Green+Blue, family = binomial, data=blueTarpTrain)
summary(glm.fit)
glm.prob <- predict(glm.fit, blueTarpTest, type = "response")
glm.pred=ifelse(glm.prob>0.5,1,0)
cm.glm <- confusionMatrix(factor(glm.pred), factor(blueTarpTest$Blue_Tarp_or_Not)) 
cm.glm

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, glm.pred, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one
```

One vs the rest for logistic regression of different classes 

##LDA 

```{r}
#fitControl <- trainControl(method = "cv")

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)

set.seed(4)
lda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="lda",
                    verbose= FALSE,
                    trControl= fitControl)

lda.fit
#summary(lda.fit)
```
### Threshold 0.5
```{r}

lda.pred <- predict(lda.fit, newdata =blueTarpTest, type = "prob")
#lda.class<-lda.pred[,"0"]
lda.class=ifelse(lda.pred[,1]>0.5,1,0)


cm.lda <- confusionMatrix(factor(lda.class), factor(blueTarpTest$Blue_Tarp_or_Not))
cm.lda
table(lda.class, blueTarpTest$Blue_Tarp_or_Not)
mean(lda.class==blueTarpTest$Blue_Tarp_or_Not)

#Threshold of 0.5
sum(lda.pred[,'1']>=0.5)
sum(lda.pred[,"1"]<0.5) #AUC 88.9%

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, lda.class, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one

```

```{r}

lda.pred <- predict(lda.fit, newdata =blueTarpTest, type = "prob")
#lda.class<-lda.pred[,"0"]
lda.class=ifelse(lda.pred[,1]>0.3,1,0)


cm.lda <- confusionMatrix(factor(lda.class), factor(blueTarpTest$Blue_Tarp_or_Not))
cm.lda
table(lda.class, blueTarpTest$Blue_Tarp_or_Not)
mean(lda.class==blueTarpTest$Blue_Tarp_or_Not)

#Threshold of 0.3
sum(lda.pred[,'1']>=0.3)
sum(lda.pred[,"1"]<0.3) #AUC 

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, lda.class, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one

```
```{r}

lda.pred <- predict(lda.fit, newdata =blueTarpTest, type = "prob")
#lda.class<-lda.pred[,"0"]
lda.class=ifelse(lda.pred[,1]>.99,1,0)


cm.lda <- confusionMatrix(factor(lda.class), factor(blueTarpTest$Blue_Tarp_or_Not))
cm.lda
table(lda.class, blueTarpTest$Blue_Tarp_or_Not)
mean(lda.class==blueTarpTest$Blue_Tarp_or_Not)

#Threshold of 0.3
sum(lda.pred[,'1']>=.99)
sum(lda.pred[,"1"]<.99) #AUC 

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, lda.class, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one

```

##QDA 

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)

set.seed(4)
qda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="qda",
                    verbose= FALSE,
                    trControl= fitControl)

qda.fit

```

### Threshold 0.5
```{r}

qda.pred <- predict(qda.fit, newdata =blueTarpTest, type = "prob")
qda.class=ifelse(qda.pred[,1]>0.5,1,0)


cm.qda <- confusionMatrix(factor(qda.class), factor(blueTarpTest$Blue_Tarp_or_Not))
cm.qda
table(qda.class, blueTarpTest$Blue_Tarp_or_Not)
mean(qda.class==blueTarpTest$Blue_Tarp_or_Not)

#Threshold of 0.5
sum(qda.pred[,'1']>=0.5)
sum(qda.pred[,"1"]<0.5) #AUC 88.9%

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, qda.class, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one

```

## Base R KNN
```{r}

knn.mod<-knn(data.frame(blueTarpTrain), data.frame(blueTarpTest), blueTarpTrain$Blue_Tarp_or_Not, k=10)

#haven't done prediction yet
cm.knn <- confusionMatrix(knn.pred, blueTarpTest$Blue_Tarp_or_Not)
cm.knn

table(knn.pred, blueTarpTest$Blue_Tarp_or_Not)
mean(knn.pred==blueTarpTest$Blue_Tarp_or_Not)
```



## KNN
```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10, #number of folds
                           repeats = 10) # number of times each fold is run; can the number of repeats be reduced? do both of these need to be 10?

set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = blueTarpTrain,
                    preProcess=c("center","scale"),
                    method="knn",
                    trControl= fitControl,
                    tuneLength=10
                    )

knn.fit

#need to put in the predictions here then feed that to the ROC curve 


```

```{r}
knn.pred <- predict(knn.mod, newdata =blueTarpTest, type = "prob")
knn.class=ifelse(knn.pred[,1]>0.5,1,0)


cm.knn <- confusionMatrix(factor(knn.class), factor(blueTarpTest$Blue_Tarp_or_Not))
cm.knn
table(knn.class, blueTarpTest$Blue_Tarp_or_Not)
mean(knn.class==blueTarpTest$Blue_Tarp_or_Not)

#Threshold of 0.5
sum(knn.pred[,'1']>=0.5)
sum(knn.pred[,"1"]<0.5) #AUC

par(pty="s")
roc(blueTarpTest$Blue_Tarp_or_Not, qda.class, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE) #need to work on this one

```


Choosing a threshold F-score is one way to help decide this... beware of the defaults 
