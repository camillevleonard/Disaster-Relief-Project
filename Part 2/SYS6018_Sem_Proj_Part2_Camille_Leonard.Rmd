---
title: "SYS 6018 Semester Project Part 2"
author: "Camille Leonard"
date: "10/31/2020"
output: 
  html_document:
    theme: spacelab 
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true 
      smooth_scroll: false 
    number_sections: true
    fig_caption: true 
    code_folding: hide  
    
    
---

# Project Introduction 

On [January 12, 2010](en.wikipedia.org/wiki/2010_Haiti_earthquake), a magnitude 7.0 earthquake struck Haiti causing significant damage which affected approximately 3 million citizens. In the wake of the disaster, aid groups were working to locate displaced persons and provide them with food and water. However, due to the large scale destruction of infrastructure over a wide area additional assistance was needed to locate people quickly. 


![Little is left of a neighborhood on a hillside near downtown Port-au-Prince on Jan. 15. More than a million people were displaced by the quake. ([David Gilkey/NPR](https://www.npr.org/sections/pictureshow/2020/01/12/794939899/haiti-in-ruins-a-look-back-at-the-2010-earthquake))](Images/NPR_destruction.jpg)


Displaced persons were known to be making make-shift shelters out of blue tarps. High resolution geo-refereneced images were captured by aircraft of the destroyed areas. The data generated by the image collection was too large for aid workers to process in time to supply aid. Therefore, a team from the [Rochester Institute of Technology](https://www.rit.edu/news/rit-captures-haiti-disaster-high-tech-imaging-system) used data-mining algorithms to analyze the images and identify blue tarps. The goal was to effectively locate displaced persons and communicate their location to rescue workers so they could get resources to people who needed it in time.  

![Sample image of a geo-referenced image used for the analysis](Images/orthovnir071_makeshift_villiage1.jpg)

As the final project for SYS 6018 - Data Mining, we were assigned to build models from the different techniques we learned in the course to, as accurately as possible, and in as timely a manner as possible, locate as many of the displaced persons identified in the imagery data so that they could be provided food and water before their situations became unsurvivable.  The data made available to students consisted of a csv of red, green, blue pixel values. A final hold-out data set  presented in the format of multiple text files was provided as well. 

# Risk Analysis / Cost Benefit / Budget for Project 
The US Government spent [$1.5B on Haiti disaster relief](https://www.rand.org/pubs/research_reports/RR304.html) by the end of 2010.  
*method of delivery
*cost of resources
*time from disaster to unsurvivable conditions 

# Analysis Methods 

```{r, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 7,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "75%", # set width of displayed images
                      warning=FALSE,     # do not show R warnings
                      message=FALSE)     # do not show R messages
```

```{r 1, echo=FALSE, message=FALSE, results='hide'}
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(caret)
library(pROC)
library(class)
library(stats)
library(ROCR)
library(randomForest)
library(e1071)
```

```{r cores, echo=FALSE, message=FALSE, results='hide'}
cores <- parallel::detectCores()
cores
```

```{r, echo=FALSE, message=FALSE, results='hide'}
all_cores <- parallel::detectCores(logical = FALSE)
all_cores
```

```{r, echo=FALSE, message=FALSE, results='hide'}
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
```

```{r, echo=FALSE, message=FALSE, results='hide'}
library(tune)
grid_control <- control_grid(verbose = TRUE,pkgs = "doParallel",allow_par = TRUE)
```
## EDA 

To begin the analysis the data set was loaded into a data frame and checked for and NA values that would have to be addressed. The data was already cleaned and did not contain any NA values.  

```{r 2}
df <- tibble(read.csv("HaitiPixels.csv")) #read in df
"Check for NA values" 
anyNA(df) #check for NA values 
summary(df) #quick look at data
```

The data provided for analysis was generated from overhead images and stored as a three channel output. The channels represented the red, green, and blue values for pixels within images. RGB color model is referred to as an additive model. The integer value for the red, green, and blue channels are combined to represent a color. Typically, the component values are stored as an 8 bit integer ranging from 0 to 255. 

The data was visualized with the ggpairs function. For a pair of variables chosen from the data frame, [Ggpairs](https://www.r-graph-gallery.com/199-correlation-matrix-with-ggally.html#:~:text=The%20ggpairs()%20function%20of,left%20part%20of%20the%20figure.&text=Variable%20distribution%20is%20available%20on%20the%20diagonal.) generates a scatterplot, displays a Pearson correlation, and, on the diagonal, shows a variable distribution. The plots were also color-coded by class. The class describes what kind of object a pixel is associated with. In our data frame there were the following classes: Blue Tarp, Rooftop, Soil, Various Non-tarp, and Vegetation. 

Inspection of the generated figure indicated that   
```{r, message=False}
#Reference [1]
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
  
df$Class <- factor(df$Class) #make Class a factor variable. 
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class))# + scale_fill_manual(values=cbPalette) 
#view scatter and correlations
attach(df) #attach df variables 
```
!!!!!!!!!! IF I HAVE TIME MAKE A SELECTOR TO CHOOSE COLOR SCHEME FOR NOT COLOR BLIND OR DIFFERENT KINDS OF COLOR BLIND https://socviz.co/refineplots.html 


!!!!!!!!!!!!! Make some comments about this figure or remove it...
```{r 3}
#take a look at the distribution of classes and RBG values 
featurePlot(x = df[,2:4],
            y = df$Class,
            plot = "box",
            layout = c(3,1), 
            scales = list(y = list(relation = "free"),
                          x = list(rot = 90)))
```


## Prepare Data Frame for Analysis 

The goal of this project is to identify blue tarps from non-blue tarps ... 

```{r 4}
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not) #ensure new column is a factor 
df
df_factor <- df[, -1]
tail(df_factor)
```


## Logistic Regression 
Fit a Logistic Regression Model 
!!!Need to turn on the fold result saving ... 
```{r Log Reg, message=FALSE, warning=FALSE}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE) 

set.seed(4)
glm.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    method="glm",
                    family="binomial",
                    trControl= fitControl)

glm.fit

summary(glm.fit)
```


Test model performance on Train data to select threshold values... 
```{r Log Reg pred}
glm.prob <- predict(glm.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
glm_roc <- roc(df_factor$Blue_Tarp_or_Not, glm.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="GLM ROC Curve") 
```

## LDA 

```{r LDA}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
lda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="lda",
                    verbose= FALSE,
                    trControl= fitControl)

lda.fit
#summary(lda.fit)
```


```{r LDA pred}
lda.prob <- predict(lda.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
lda_roc <- roc(df_factor$Blue_Tarp_or_Not, lda.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="LDA ROC Curve") 
```


## QDA 

```{r QDA}

fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
qda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="qda",
                    verbose= FALSE,
                    trControl= fitControl)

qda.fit

```

```{r QDA pred}

qda.prob <- predict(qda.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
qda_roc <- roc(df_factor$Blue_Tarp_or_Not, qda.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="QDA ROC Curve") 
```

## KNN 

```{r KNN}

fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="knn",
                    trControl= fitControl,
                    tuneLength=5
                    )

knn.fit


```

```{r KNN pred}

knn.prob <- predict(knn.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
knn_roc <- roc(df_factor$Blue_Tarp_or_Not, knn.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="KNN ROC Curve") 
```

## Random Forest 

```{r Random Forest}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
rf.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="rf", #what is the difference between the different caret rf models??
                    trControl= fitControl,
                    tuneLength=3
                    )

rf.fit
```


## SVM
```{r SVM Radial}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
svm.radial.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="svmRadial",
                    trControl= fitControl,
                    tuneLength=3
                    )

svm.radial.fit
```
```{r SVM Linear}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
svm.linear.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="svmLinear",
                    trControl= fitControl,
                    tuneLength=3
                    )

svm.linear.fit
```

```{r SVM Poly}
fitControl <- trainControl(method = "cv",
                           number = 10,
                           returnResamp = 'all',
                           savePredictions = 'final',
                           classProbs = TRUE)

set.seed(4)
svm.poly.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
                    data = df_factor,
                    preProcess=c("center","scale"),
                    method="svmPoly",
                    trControl= fitControl,
                    tuneLength=3
                    )

svm.poly.fit
```

The final values used for the model were degree = 3, scale = 0.1 and C = 1.

## K-Folds Out of Sampling Performance 

### Table 2 - Performance Metrics: 10-Fold Cross-Validation Metrics 

!!!!! THESE VALUES HAVE NOT BEEN UPDATED, POSSIBLY CONSIDER AUTOMATING THEM  

|                   Method | KNN (k = 5)  |    LDA    |    QDA    | Log. Regression | Random Forest (tuning param = ?) | SVM (tuning param = ?)|
|-------------------------:|:------------:|:---------:|:---------:|:---------------:|:--------------------------------:|:---------------------:|
|                 Accuracy | 99.6%        | 98.2%     | 98.9%     | 99.2%           | | |
|                      AUC | 100%         | 98.9%     | 99.8%     | 99.8%           | | |
|                      ROC |              |           |           |                 | | |
|                Threshold | 0.077        | 0.10      | 0.10      | 0.15            | | |
| Sensitivity=Recall=Power | 98.8%        | 84.7%     | 90.0%     | 94.6%           | | |
|        Specificity=1-FPR | 99.7%        | 98.7%     | 99.3%     | 99.3%           | | |
|                      FDR | 9.6%         | 32.3%     | 19.6%     | 18.3%           | | |
|            Precision=PPV | 90.4%        | 67.3%     | 80.4%     | 81.7%           | | |

## Model Performance 

```{r, echo=FALSE}
parallel::stopCluster(cl)
```
### Discussion 
(discussion on FHO data why we do this... what the benefits are... potential pitfalls)

(discussion somewhere about ROC curves AUC and... other metrics)

## Hold-Out Test Sample Performance 

### Table 3 - Performance Metrics: Hold-Out Test Data Set Scores  

!!!!! THESE VALUES HAVE NOT BEEN UPDATED, POSSIBLY CONSIDER AUTOMATING THEM  

|                   Method | KNN (k = 5)  |    LDA    |    QDA    | Log. Regression | Random Forest (tuning param = ?) | SVM (tuning param = ?)|
|-------------------------:|:------------:|:---------:|:---------:|:---------------:|:--------------------------------:|:---------------------:|
|                 Accuracy | 99.6%        | 98.2%     | 98.9%     | 99.2%           | | |
|                      AUC | 100%         | 98.9%     | 99.8%     | 99.8%           | | |
|                      ROC |              |           |           |                 | | |
|                Threshold | 0.077        | 0.10      | 0.10      | 0.15            | | |
| Sensitivity=Recall=Power | 98.8%        | 84.7%     | 90.0%     | 94.6%           | | |
|        Specificity=1-FPR | 99.7%        | 98.7%     | 99.3%     | 99.3%           | | |
|                      FDR | 9.6%         | 32.3%     | 19.6%     | 18.3%           | | |
|            Precision=PPV | 90.4%        | 67.3%     | 80.4%     | 81.7%           | | |


## Future Work 
```{r}
#consider if I was able to find an additional data source like lidar or infrared to pair with this dataset to improve model performance... ? 
```

# References and Works Cited 

[1] http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette 
* Thanks to Derek Banks for sharing code for doing multicore processing
* Assigning color to ggplot scatter: https://www.r-graph-gallery.com/ggplot2-color.html
* Change correlation text size ggpairs : https://stackoverflow.com/questions/8599685/how-to-change-correlation-text-size-in-ggpairs
* Information on RGB color model: https://en.wikipedia.org/wiki/RGB_color_model
* Inspiration to color-code the ggpairs figure came from Professor Schwartz showing us another student's project [Michael Davies] in class.  

# Appendix A: Analysis Methods Reference Info





