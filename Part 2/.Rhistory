install.packages(c("doParallel", "tune"))
setwd("D:/Docs/MSDS - UVA/Fall 2020/SYS 6018 - Data Mining/Semester-Project/Part 2")
setwd("D:/Docs/MSDS - UVA/Fall 2020/SYS 6018 - Data Mining/Semester-Project/Part 2")
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
collapse=FALSE,    # collapse by default
echo=TRUE,         # echo code by default
comment = "#>",    # change comment character
fig.width = 7,     # set figure width
fig.align = "center",# set figure position
out.width = "75%", # set width of displayed images
warning=FALSE,     # do not show R warnings
message=FALSE)     # do not show R messages
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(caret)
library(pROC)
library(class)
library(stats)
library(ROCR)
library(randomForest)
library(e1071)
cores <- parallel::detectCores()
cores
all_cores <- parallel::detectCores(logical = FALSE)
all_cores
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
library(tune)
grid_control <- control_grid(verbose = TRUE,pkgs = "doParallel",allow_par = TRUE)
df <- tibble(read.csv("HaitiPixels.csv")) #read in df
"Check for NA values"
anyNA(df) #check for NA values
summary(df) #quick look at data
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class)) #view scatter and correlations
attach(df) #attach df variables
#take a look at the distribution of classes and RBG values
featurePlot(x = df[,2:4],
y = df$Class,
plot = "box",
layout = c(3,1),
scales = list(y = list(relation = "free"),
x = list(rot = 90)))
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class), scale_fill_manual(values=cbPalette)) #view scatter and correlations
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class, scale_fill_manual(values=cbPalette))) #view scatter and correlations
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class, x=scale_fill_manual(values=cbPalette))) #view scatter and correlations
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class)) + scale_fill_manual(values=cbPalette) #view scatter and correlations
attach(df) #attach df variables
#Reference [1]
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class)) + scale_fill_manual(values=cbPalette) + scale_fill_hue(values=cbPalette)
#Reference [1]
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class)) + mapping(scale_fill_manual(values=cbPalette) + scale_fill_hue(values=cbPalette))
#Reference [1]
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class)) + scale_fill_manual(values=cbPalette)
#view scatter and correlations
attach(df) #attach df variables
#Reference [1]
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# To use for fills, add
#scale_fill_manual(values=cbPalette)
df$Class <- factor(df$Class) #make Class a factor variable.
ggpairs(df[,2:4], lower.panel = NULL, upper = list(continuous = wrap("cor", size = 3)), aes(color=df$Class))# + scale_fill_manual(values=cbPalette)
#view scatter and correlations
attach(df) #attach df variables
#take a look at the distribution of classes and RBG values
featurePlot(x = df[,2:4],
y = df$Class,
plot = "box",
layout = c(3,1),
scales = list(y = list(relation = "free"),
x = list(rot = 90)))
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
glm.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
method="glm",
family="binomial",
trControl= fitControl)
glm.fit
summary(glm.fit)
pass
glm.prob <- predict(glm.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
glm.prob <- predict(glm.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
glm_roc <- roc(df_factor$Blue_Tarp_or_Not, glm.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="GLM ROC Curve")
glm.prob <- predict(glm.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
glm.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
method="glm",
family="binomial",
trControl= fitControl)
?as.factor
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not, levels=c(0,1), labels=c("NBT", "BT")) #ensure new column is a factor
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not, labels=c("NBT", "BT")) #ensure new column is a factor
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not, levels=c("0","1"), labels=c("NBT", "BT")) #ensure new column is a factor
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
Blue_Tarp_or_Not <- as.factor(Blue_Tarp_or_Not, levels=c("0","1"), labels=c("NBT", "BT")) #ensure new column is a factor
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c("0","1"), labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c("0","1"), labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c(0,1), labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not,  labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
View(df)
View(df)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c("NBT", "BT"), labels=c(0,1)) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c(0,1), labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not,  labels=c("NBT", "BT")) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
View(df)
View(df)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not, levels=c(0,1)) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
df <- cbind(mutate(df, "Blue_Tarp_or_Not"=ifelse(Class != "Blue Tarp", 0, 1))) #add binary column indicating whether the Class variable is "Blue Tarp" or not
attach(df)
df$Blue_Tarp_or_Not <- factor(Blue_Tarp_or_Not) #ensure new column is a factor
df
df_factor <- df[, -1]
tail(df_factor)
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
glm.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
method="glm",
family="binomial",
trControl= fitControl)
glm.fit
summary(glm.fit)
glm.prob <- predict(glm.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
glm_roc <- roc(df_factor$Blue_Tarp_or_Not, glm.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="GLM ROC Curve")
pass
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10)
set.seed(4)
lda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="lda",
verbose= FALSE,
trControl= fitControl)
lda.fit
#summary(lda.fit)
lda.prob <- predict(lda.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
lda_roc <- roc(df_factor$Blue_Tarp_or_Not, lda.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="LDA ROC Curve")
pass
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10)
set.seed(4)
qda.fit <- caret::train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="qda",
verbose= FALSE,
trControl= fitControl)
qda.fit
pass
qda.prob <- predict(qda.fit, newdata=df_factor, type = "prob") #returns df with col 0 (prob not blue tarp) and 1 (prob blue tarp)
par(pty="s")
qda_roc <- roc(df_factor$Blue_Tarp_or_Not, qda.prob[,2], plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="#965fd4", lwd=4, print.auc=TRUE, main="QDA ROC Curve")
pass
fitControl <- trainControl(method = "repeatedcv",
number = 10, #number of folds
repeats = 10) # number of times each fold is run; can the number of repeats be reduced? do both of these need to be 10?
set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="knn",
trControl= fitControl,
tuneLength=10
)
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="knn",
trControl= fitControl,
tuneLength=3
)
knn.fit
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
knn.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="knn",
trControl= fitControl,
tuneLength=5
)
knn.fit
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
rf.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="rf", #what is the difference between the different caret rf models??
trControl= fitControl,
tuneLength=3
)
rf.fit
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
svm.radial.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="svmRadial",
trControl= fitControl,
tuneLength=3
)
svm.radial.fit
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
svm.linear.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="svmLinear",
trControl= fitControl,
tuneLength=3
)
svm.linear.fit
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
svm.poly.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="svmPoly",
trControl= fitControl,
tuneLength=3
)
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
collapse=FALSE,    # collapse by default
echo=TRUE,         # echo code by default
comment = "#>",    # change comment character
fig.width = 7,     # set figure width
fig.align = "center",# set figure position
out.width = "75%", # set width of displayed images
warning=FALSE,     # do not show R warnings
message=FALSE)     # do not show R messages
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(caret)
library(pROC)
library(class)
library(stats)
library(ROCR)
library(randomForest)
library(e1071)
cores <- parallel::detectCores()
cores
all_cores <- parallel::detectCores(logical = FALSE)
all_cores
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
library(tune)
grid_control <- control_grid(verbose = TRUE,pkgs = "doParallel",allow_par = TRUE)
parallel::stopCluster(cl)
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
collapse=FALSE,    # collapse by default
echo=TRUE,         # echo code by default
comment = "#>",    # change comment character
fig.width = 7,     # set figure width
fig.align = "center",# set figure position
out.width = "75%", # set width of displayed images
warning=FALSE,     # do not show R warnings
message=FALSE)     # do not show R messages
library(tidyverse)
library(MASS)
library(ggplot2)
library(GGally)
library(caret)
library(pROC)
library(class)
library(stats)
library(ROCR)
library(randomForest)
library(e1071)
cores <- parallel::detectCores()
cores
all_cores <- parallel::detectCores(logical = FALSE)
all_cores
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
library(tune)
grid_control <- control_grid(verbose = TRUE,pkgs = "doParallel",allow_par = TRUE)
fitControl <- trainControl(method = "cv",
number = 10,
returnResamp = 'all',
savePredictions = 'final',
classProbs = TRUE)
set.seed(4)
svm.poly.fit <- train(Blue_Tarp_or_Not~Red+Green+Blue,
data = df_factor,
preProcess=c("center","scale"),
method="svmPoly",
trControl= fitControl,
tuneLength=3
)
svm.poly.fit
